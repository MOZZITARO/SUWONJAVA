import urllib.parse
import requests
from googleapiclient.discovery import build
import urllib.request
import json
import httpx
import asyncio
import os
from dotenv import load_dotenv
import google.generativeai as genai
import re
from konlpy.tag import Okt
import random

load_dotenv()

GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if GOOGLE_API_KEY:
    genai.configure(api_key=GOOGLE_API_KEY)
    gemini_text_model = genai.GenerativeModel("gemini-1.5-flash")
else:
    gemini_text_model = None
    print("### ê²½ê³ : GOOGLE_API_KEYê°€ ì—†ì–´ì„œ Gemini ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

PUBLIC_API_KEY = os.getenv("PUBLIC_API_KEY")
OLLAMA_API_URL = os.getenv("OLLAMA_API_URL")
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL")


# OLLAMA_API_URL = "http://localhost:11434/api/generate"
# OLLAMA_MODEL = "gemma3:4b"


# geminiê°€ ê³µê³µë°ì´í„° apië¡œ ê°€ì ¸ì˜¨ ë ˆì‹œí”¼ ë°ì´í„°ì˜ ì¬ë£Œë¶€ë¶„ì„ íŒŒì‹±
async def parse_ingredients_with_gemini(raw_text: str) -> list[dict]:
    """Geminië¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ì •í˜•ì ì¸ ì¬ë£Œ í…ìŠ¤íŠ¸ë¥¼ [{"name": ..., "quantity": ..., "description": ...}] í˜•ì‹ìœ¼ë¡œ íŒŒì‹±."""

    if not gemini_text_model:
        return []

    prompt = f"""
        ë‹¹ì‹ ì€ ë¹„ì •í˜•ì ì¸ ìš”ë¦¬ ì¬ë£Œ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬, êµ¬ì¡°í™”ëœ JSON ë°°ì—´ë¡œ ë³€í™˜í•˜ëŠ” ë§¤ìš° ì •ë°€í•œ íŒŒì‹± AIì…ë‹ˆë‹¤.
        ì£¼ì–´ì§„ [ì›ë³¸ í…ìŠ¤íŠ¸]ì—ì„œ ìˆœìˆ˜í•œ 'ì¬ë£Œ' ì •ë³´ë§Œ ì¶”ì¶œí•˜ì—¬, ì•„ë˜ [ê·œì¹™]ê³¼ [ì¶œë ¥ í˜•ì‹]ì„ ì ˆëŒ€ì ìœ¼ë¡œ ì¤€ìˆ˜í•˜ëŠ” JSON ë°°ì—´ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
        
        [ê·œì¹™]
        1.  **í•µì‹¬ ë¶„ë¦¬**: ê° ì¬ë£Œ í•­ëª©ì„ 'name', 'quantity', 'description' ì„¸ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.
            -   `name`: ì¬ë£Œì˜ ìˆœìˆ˜í•œ ì´ë¦„ (ì˜ˆ: 'ì—°ë‘ë¶€', 'ì¹µí…Œì¼ìƒˆìš°', 'ë‹¤ì§„ ëŒ€íŒŒ')
            -   `quantity`: ì¬ë£Œì˜ ì–‘ê³¼ ë‹¨ìœ„. ìˆ«ìì™€ ë‹¨ìœ„(g, kg, ml ë“±)ë¥¼ í¬í•¨í•©ë‹ˆë‹¤. (ì˜ˆ: '75g', '2ml', '300ml', 'ì•½ê°„')
            -   `description`: ê´„í˜¸ '()' ì•ˆì— ìˆëŠ” ë¶€ê°€ ì„¤ëª…. (ì˜ˆ: '3/4ëª¨', '5ì¤„ê¸°', '1/3ì‘ì€ìˆ ', '1/2ìª½', '1/8ë´‰ì§€')
        2.  **ë…¸ì´ì¦ˆ ì œê±°**: 'ìƒˆìš°ë‘ë¶€ê³„ë€ì°œ', 'â—ë°©ìš¸í† ë§ˆí†  ì†Œë°•ì´ :', '[1ì¸ë¶„]', 'ê³ ëª…' ë“± ìš”ë¦¬ ì´ë¦„ì´ë‚˜ ì¹´í…Œê³ ë¦¬ëª…ì€ **ì™„ì „íˆ ë¬´ì‹œí•˜ê³  ê²°ê³¼ì— í¬í•¨ì‹œí‚¤ì§€ ë§ˆì„¸ìš”.**
        3.  **ì„¹ì…˜ ì²˜ë¦¬**: 'Â·ì–‘ë…ì¥ :', 'â—ì†ŒìŠ¤ :' ë“±ê³¼ ê°™ì´ ì—¬ëŸ¬ ì¬ë£Œë¥¼ í¬í•¨í•˜ëŠ” ì„¹ì…˜ì´ ìˆë‹¤ë©´, ê·¸ ì•ˆì— ìˆëŠ” ê° ì¬ë£Œë“¤ì„ ê°œë³„ í•­ëª©ìœ¼ë¡œ ëª¨ë‘ ì¶”ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.
        4.  **ì¼ê´€ì„±**: ì–‘ì´ë‚˜ ì„¤ëª…ì´ ì—†ëŠ” ê²½ìš°, í•´ë‹¹ ê°’ì€ ë¹ˆ ë¬¸ìì—´("")ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.

        [ìƒì„¸ ì˜ˆì‹œ]
        -   "ì—°ë‘ë¶€ 75g(3/4ëª¨)" -> {{"name": "ì—°ë‘ë¶€", "quantity": "75g", "description": "3/4ëª¨"}}
        -   "ì°¸ê¹¨ ì•½ê°„" -> {{"name": "ì°¸ê¹¨", "quantity": "ì•½ê°„", "description": ""}}
        -   "ë¬¼ 300ml(1Â½ì»µ)" -> {{"name": "ë¬¼", "quantity": "300ml", "description": "1Â½ì»µ"}}

        [ì›ë³¸ í…ìŠ¤íŠ¸]
        {raw_text}

        [ì¶œë ¥ í˜•ì‹]
        [
        {{"name": "ì¬ë£Œ1 ì´ë¦„", "quantity": "ì¬ë£Œ1 ì–‘", "description": "ì¬ë£Œ1 ì„¤ëª…"}},
        {{"name": "ì¬ë£Œ2 ì´ë¦„", "quantity": "ì¬ë£Œ2 ì–‘", "description": "ì¬ë£Œ2 ì„¤ëª…"}}
        ]
    """

    try:
        response = await gemini_text_model.generate_content_async([prompt])

        # Gemini ì‘ë‹µì—ì„œ JSON ë¶€ë¶„ë§Œ ì •í™•íˆ ì¶”ì¶œ
        json_text_match = re.search(r"\[\s*\{.*?\}\s*\]", response.text, re.DOTALL)
        if not json_text_match:
            print("### Gemini íŒŒì‹± ì˜¤ë¥˜: ì‘ë‹µì—ì„œ ìœ íš¨í•œ JSON ë°°ì—´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

            return []

        return json.loads(json_text_match.group())

    except Exception as e:
        print(f"### Gemini ì¬ë£Œ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []


# geminiê°€ ì§ˆë¬¸ì— ë‹µë³€
async def answer_user_question_with_gemini(
    question: str, subject: str, context_recipe: dict = None
) -> str:
    """ì£¼ì–´ì§„ ì£¼ì œì™€ ë§¥ë½(ì´ì „ ì¶”ì²œ ë ˆì‹œí”¼)ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€"""

    if not gemini_text_model:
        return "ì£„ì†¡í•´ìš”. ì§€ê¸ˆì€ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ì—†ì–´ìš”..."

    # ë§¥ë½ ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
    context_info = ""
    if context_recipe:
        recipe_name = context_recipe.get("name", "í•´ë‹¹ ë ˆì‹œí”¼")
        ingredients_str = ", ".join(
            [ing["name"] for ing in context_recipe.get("ingredients", [])]
        )
        instructions_str = "\n".join(
            [
                f"{inst['step_num']}. {inst['description']}"
                for inst in context_recipe.get("instructions", [])
            ]
        )
        context_info = f"""
            [ì°¸ê³  ë ˆì‹œí”¼ ì´ë¦„: '{recipe_name}']
            - ì‚¬ìš©í•˜ëŠ” ì¬ë£Œ : {ingredients_str}
            - ì¡°ë¦¬ë²• ìš”ì•½ : {instructions_str}
        """

    prompt = f"""
        ë‹¹ì‹ ì€ ìƒëƒ¥í•˜ê³  ìœ ëŠ¥í•œ 'ëƒ‰ì¥ê³  ìš”ë¦¬ì‚¬' ì±—ë´‡ì…ë‹ˆë‹¤.
        ì•„ë˜ ì°¸ê³  ì •ë³´ì™€ ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ, ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•˜ê³  ìƒì„¸í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
        ëª¨ë¥´ëŠ” ë‚´ìš©ì€ ëª¨ë¥¸ë‹¤ê³  ì†”ì§í•˜ê²Œ ë‹µí•˜ê³ , í•­ìƒ ê¸ì •ì ì¸ íƒœë„ë¥¼ ìœ ì§€í•˜ì„¸ìš”.
        
        {context_info}
        
        ì‚¬ìš©ì ì§ˆë¬¸: "{question}" (ì£¼ì œ: {subject})
    """

    try:
        response = await gemini_text_model.generate_content_async([prompt])
        return response.text.strip()
    except Exception as e:
        print(f"### Gemini ì§ˆë¬¸ ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {e}")
        return "ì£„ì†¡í•´ìš”. ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì— ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”."


# geminiê°€ ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ ë¶„ì„
async def analyze_user_intent_with_gemini(
    message: str, chat_history: list = None
) -> dict:
    """ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì˜ë„, í¬í•¨í•  ì¬ë£Œ, ì œì™¸í•  ì¬ë£Œë¥¼ ì¶”ì¶œ"""

    # ëŒ€í™” ê¸°ë¡ì„ í”„ë¡¬í”„íŠ¸ì— ë„£ê¸° ì¢‹ê²Œ í¬ë§·íŒ…
    formatted_history = ""
    if chat_history:
        for msg in chat_history:
            role = "ì‚¬ìš©ì" if msg["sender"] == "user" else "ì±—ë´‡"
            formatted_history += f"{role}: {msg['content']}\n"

    if not gemini_text_model:
        return {"intent": "unknown"}

    prompt = f"""
    
        ë‹¹ì‹ ì€ ì±—ë´‡ì˜ ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
        ì•„ë˜ 'ëŒ€í™” ê¸°ë¡'ì„ ì°¸ê³ í•˜ì—¬, 'ìƒˆë¡œìš´ ì‚¬ìš©ì ë©”ì‹œì§€'ì˜ ì§„ì§œ ì˜ë„ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.
        ë¶„ì„ ê²°ê³¼ëŠ” 'intent', 'subject', 'include_ingredients', 'exclude_ingredients' ë„¤ ê°€ì§€ í‚¤ë¥¼ ê°€ì§„ JSON ê°ì²´ë¡œë§Œ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.
        
        [ëŒ€í™” ê¸°ë¡]
        {formatted_history}
        [ìƒˆë¡œìš´ ì‚¬ìš©ì ë©”ì‹œì§€]
        {message}
        
        [ë¶„ì„ ê°€ì´ë“œ]
        - intent: 'request_recipe'(ìƒˆë¡œìš´ ë ˆì‹œí”¼ ì¶”ì²œ ìš”ì²­), 'request_next_recipe'(ì´ì „ì— ì¶”ì²œí•œ ëª©ë¡ì—ì„œ ë‹¤ìŒ ê²ƒ ìš”ì²­), 'ask_question'(ë‹¨ìˆœ ì§ˆë¬¸), 'greeting'(ì¸ì‚¬) ì¤‘ í•˜ë‚˜.
        - subject: 'ask_question'ì¼ ë•Œ, ì§ˆë¬¸ì˜ ëŒ€ìƒì´ ë˜ëŠ” ìŒì‹ì´ë‚˜ ì£¼ì œ. (ì˜ˆ: "ì‚¬ê³¼íŒŒì´ ë§Œë“¤ê¸°", "ê·¸ ë ˆì‹œí”¼")
        - include_ingredients: ì‚¬ìš©ìê°€ ì‚¬ìš©í•˜ê³  ì‹¶ì–´í•˜ëŠ” ì¬ë£Œ. ëŒ€í™” ë¬¸ë§¥ì„ íŒŒì•…í•´ì•¼í•¨. (ì˜ˆ: "ê·¸ê±¸ë¡œ ë§Œë“¤ì–´ì¤˜" -> 'ê·¸ê²ƒ'ì´ ì´ì „ ëŒ€í™”ì˜ ì¬ë£Œë¥¼ ì˜ë¯¸)
        - exclude_ingredients: ì‚¬ìš©ìê°€ ë¹¼ê³  ì‹¶ì–´í•˜ëŠ” ì¬ë£Œ. (ì˜ˆ: "ë¼ì§€ê³ ê¸°ê°€ ì•ˆë“¤ì–´ê°„ ì¹´ë ˆ ë ˆì‹œí”¼ ì¶”ì²œí•´ì¤˜" -> 'ë¼ì§€ê³ ê¸°'ë¥¼ ì œì™¸ ì¬ë£Œë¡œ ì¸ì‹ ê°€ëŠ¥)
        - 'ê·¸ê±° ë§ê³ ', 'ë‹¤ë¥¸ ê±° ë³´ì—¬ì¤˜', 'ë³„ë¡œì•¼' ì™€ ê°™ì€ ë¶€ì •ì ì¸ í”¼ë“œë°±ì€ 'request_next_recipe'ë¡œ ë¶„ë¥˜.
        - 'ì¬ë£Œ'ë¥¼ ëª…ì‹œí•˜ë©´ 'request_recipe'ë¡œ ë¶„ë¥˜.
        
        [ì˜ˆì‹œ]
        - ëŒ€í™”ê¸°ë¡: "ì±—ë´‡: 'ë¼ì§€ê³ ê¸° ê¹€ì¹˜ì°Œê°œ'ëŠ” ì–´ë– ì„¸ìš”?" / ìƒˆë¡œìš´ ë©”ì‹œì§€: "ê·¸ê±° ë§ê³  ë‹¤ë¥¸ê±° ì¶”ì²œí•´ì¤˜"
        -> {{"intent": "request_next_recipe", "include_ingredients": [], "exclude_ingredients": []}}
        - ëŒ€í™”ê¸°ë¡: "" / ìƒˆë¡œìš´ ë©”ì‹œì§€: "ì˜¤ëŠ˜ ì €ë… ë­ ë¨¹ì§€?"
        -> {{"intent": "request_recipe", "include_ingredients": [], "exclude_ingredients": []}}
        - ëŒ€í™”ê¸°ë¡: "" / ìƒˆë¡œìš´ ë©”ì‹œì§€: "ì†Œê³ ê¸°ë‘ ë¬´ê°€ ìˆì–´"
        -> {{"intent": "request_recipe", "include_ingredients": ["ì†Œê³ ê¸°", "ë¬´"], "exclude_ingredients": []}}
        - ëŒ€í™”ê¸°ë¡: "ì±—ë´‡: 'ì‚¬ê³¼íŒŒì´'ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤." / ìƒˆë¡œìš´ ë©”ì‹œì§€: "ë§Œë“œëŠ” ê±° ì–´ë ¤ì›Œ?"
        -> {{"intent": "ask_question", "subject": "ì‚¬ê³¼íŒŒì´ ë§Œë“¤ê¸°", "include_ingredients": [], "exclude_ingredients": []}}
    """
    # ë‚˜ì¤‘ì— ì¶”ê°€í•  ì‹œë‚˜ë¦¬ì˜¤ - ë ˆì‹œí”¼ ì´ë¦„ì´ ì¶”ê°€!!
    # 1. ì¬ë£Œë¥¼ ë§í•˜ì§€ì•Šê³  ë ˆì‹œí”¼ ì´ë¦„ë§Œ ë§í•  ê²½ìš°.. -> ëœì¥ì°Œê°œ ë ˆì‹œí”¼ ì•Œë ¤ì¤˜, ëœì¥ì°Œê°œ ë§Œë“œëŠ” ë²• ì•Œë ¤ì¤˜
    # 2. ì¬ë£Œì™€ ë ˆì‹œí”¼ëª…ì„ ê°™ì´ ë§í•  ê²½ìš°.. -> ë¼ì§€ê³ ê¸° ê¹€ì¹˜ì°Œê°œ ë ˆì‹œí”¼ ì•Œë ¤ì¤˜, ë¼ì§€ê³ ê¸° ê¹€ì¹˜ì°Œê°œ ë§Œë“œëŠ” ë²• ì•Œë ¤ì¤˜
    # 3. ë„£ì–´ì•¼í•  ì¬ë£Œ ì—†ì´, ì œì™¸í•  ì¬ë£Œë§Œ ì–¸ê¸‰í–ˆì„ ë•Œì˜ ë ˆì‹œí”¼ ì¶”ì²œ -> ê¹€ì¹˜ê°€ ì•ˆë“¤ì–´ê°„ ê¹€ì¹˜ì°Œê°œ ë ˆì‹œí”¼ ì•Œë ¤ì¤˜, ê¹€ì¹˜ê°€ ì•ˆë“¤ì–´ê°„ ê¹€ì¹˜ì°Œê°œ ë§Œë“œëŠ” ë²• ì•Œë ¤ì¤˜
    # 4. ì§ˆë¬¸ì— ë„ˆë¬´ ë§ì€ ì¬ë£Œë¥¼ í¬í•¨í•´ì„œ ë ˆì‹œí”¼ì˜ ê²°ê³¼ê°€ ì•ˆë‚˜ì˜¤ëŠ” ê²½ìš° -> ì–´ëŠ ì •ë„ê¹Œì§€ ì¬ë£Œë¥¼ ì»·í•  ê²ƒì¸ê°€.. ë˜ëŠ” ê·¸ëƒ¥ ë ˆì‹œí”¼ê°€ ì—†ë‹¤ê³  ëŒ€ë‹µ.
    try:
        response = await gemini_text_model.generate_content_async([prompt])

        # gemini ì‘ë‹µì—ì„œ json ë¶€ë¶„ë§Œ ì¶”ì¶œ
        json_text = re.search(r"\{.*\}", response.text, re.DOTALL).group()
        return json.loads(json_text)

    except Exception as e:
        print(f"### Gemini ì˜ë„ ë¶„ì„ ì˜¤ë¥˜: {e}")

        # ì˜ë„ ë¶„ì„ ì‹¤íŒ¨ ì‹œ, ê¸°ì¡´ Konlpy ë°©ì‹ ì‚¬ìš©
        okt = Okt()
        nouns = okt.nouns(message)
        return {
            "intent": "request_recipe",
            "include_ingredients": nouns,
            "exclude_ingredients": [],
        }


# geminië¥¼ ì‚¬ìš©í•´ì„œ ìì—°ìŠ¤ëŸ¬ìš´ ì±—ë´‡ ì‘ë‹µì„ ìƒì„±
async def generate_natural_chat_response(base_message: str, recipe_name: str) -> str:
    """ì£¼ì–´ì§„ ìƒí™©ê³¼ ë ˆì‹œí”¼ ì´ë¦„ì„ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ì±—ë´‡ ì‘ë‹µì„ ìƒì„±"""

    if not gemini_text_model:
        return f"{base_message}, '{recipe_name}' ë ˆì‹œí”¼ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤!"

    prompt = f"""
        ë‹¹ì‹ ì€ ì‚¬ìš©ìì™€ ì¹œê·¼í•˜ê²Œ ëŒ€í™”í•˜ëŠ” 'ëƒ‰ì¥ê³  ìš”ë¦¬ì‚¬' ì±—ë´‡ì…ë‹ˆë‹¤. ì•„ë˜ ìƒí™©ì´ ë§ëŠ”, ë‹¤ì •í•˜ê³  ì°½ì˜ì ì¸ ì¶”ì²œ ë©”ì‹œì§€ë¥¼ 1~2ë¬¸ì¥ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
        
        ìƒí™©: {base_message}
        ì¶”ì²œí•  ë ˆì‹œí”¼: {recipe_name}
        
        ì˜ˆì‹œ1 : "ì˜¤, {base_message}êµ°ìš”! ë§ˆì¹¨ ë”± ì¢‹ì€ê²Œ ìƒê°ë‚¬ì–´ìš”. ë§¤ì½¤í•œ '{recipe_name}' ì–´ë– ì„¸ìš”? ì…ë§›ì´ í™• ì‚´ì•„ë‚  ê±°ì˜ˆìš”! ğŸ˜„"
        ì˜ˆì‹œ2: "{base_message}ë¼ë‹ˆ, íƒì›”í•œ ì„ íƒì´ì—ìš”! ê·¸ëŸ¼ ì˜¤ëŠ˜ì€ ë¶€ë“œëŸ½ê³  ë“ ë“ í•œ '{recipe_name}'ìœ¼ë¡œ ë§›ìˆëŠ” í•œ ë¼ ì–´ë– ì‹ ê°€ìš”?"
    """

    try:
        response = await gemini_text_model.generate_content_async([prompt])
        return response.text.strip()
    except Exception as e:
        print(f"### Gemini ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
        return f"{base_message}, '{recipe_name}' ë ˆì‹œí”¼ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤!"


# geminië¥¼ ì‚¬ìš©í•´ì„œ ë ˆì‹œí”¼ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë©”ì†Œë“œ
async def fetch_recipe_from_gemini(ingredients: list) -> list:
    """ì£¼ì–´ì§„ ì¬ë£Œ ëª©ë¡ìœ¼ë¡œ geminië¥¼ ì‚¬ìš©í•˜ì—¬ DB ìŠ¤í‚¤ë§ˆì™€ ìœ ì‚¬í•œ êµ¬ì¡°ì˜ ë ˆì‹œí”¼ 3ê°œë¥¼ ìƒì„±"""

    if not gemini_text_model:
        return []

    ingredients_str = ", ".join(ingredients)
    print(f"### Gemini API í˜¸ì¶œ ì‹œì‘ (DB êµ¬ì¡° ë§ì¶¤) - ì¬ë£Œ: {ingredients_str}")

    # Geminiì—ê²Œ ì—­í• ì„ ë¶€ì—¬í•˜ê³ , ì¶œë ¥ í˜•ì‹ì„ ë§¤ìš° êµ¬ì²´ì ìœ¼ë¡œ ì§€ì‹œí•©ë‹ˆë‹¤.
    prompt = f"""
    ë‹¹ì‹ ì€ ë°ì´í„°ë² ì´ìŠ¤ ì…ë ¥ì„ ìœ„í•œ JSON ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” APIì…ë‹ˆë‹¤.
    ì£¼ì–´ì§„ ì¬ë£Œ '{", ".join(ingredients)}'ë¥¼ ë°˜ë“œì‹œ ì‚¬ìš©í•˜ëŠ” **ì„œë¡œ ë‹¤ë¥¸, ì°½ì˜ì ì¸** í•œêµ­ ìš”ë¦¬ ë ˆì‹œí”¼ë¥¼ **ìµœëŒ€ 3ê°œ** ìƒì„±í•´ì£¼ì„¸ìš”.
    **ê° ë ˆì‹œí”¼ì˜ "RCP_NM" ê°’ì€ ë°˜ë“œì‹œ ê³ ìœ í•´ì•¼ í•©ë‹ˆë‹¤.**
    ì‘ë‹µì€ ë°˜ë“œì‹œ ì•„ë˜ì˜ í˜•ì‹ì„ ì •í™•íˆ ì§€í‚¤ëŠ” **JSON ë°°ì—´(Array)**ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
    ê° ë°°ì—´ì˜ ìš”ì†ŒëŠ” í•˜ë‚˜ì˜ ë ˆì‹œí”¼ë¥¼ ë‚˜íƒ€ë‚´ëŠ” JSON ê°ì²´ì…ë‹ˆë‹¤.
    ê°’(value)ì€ ëª¨ë‘ ë¬¸ìì—´(string) ë˜ëŠ” ìˆ«ì(integer)ì—¬ì•¼ í•©ë‹ˆë‹¤. 
    ì‹¤ì œ ë°ì´í„°ì²˜ëŸ¼ í˜„ì‹¤ì ì¸ ê°’ì„ ìƒì„±í•´ì£¼ì„¸ìš”. ë§ˆí¬ë‹¤ìš´ì´ë‚˜ ì¶”ê°€ ì„¤ëª… ì—†ì´ ì˜¤ì§ JSON ë°°ì—´ë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.
    [
        {{
            "RCP_NM": "ì²«ë²ˆì§¸ ì°½ì˜ì ì¸ í•œê¸€ ìš”ë¦¬ ì´ë¦„",
            "RCP_WAY2": "ì˜ˆ: êµ½ê¸°, ë“ì´ê¸°, íŠ€ê¸°ê¸°, ë¬´ì¹¨, ë³¶ìŒ ì¤‘ í•˜ë‚˜",
            "RCP_PAT2": "ì˜ˆ: ë°˜ì°¬, ì¼í’ˆ, í›„ì‹, êµ­&ì°Œê°œ ì¤‘ í•˜ë‚˜",
            "INFO_WGT": "",
            "INFO_ENG": "ì¹¼ë¡œë¦¬(kcal) ìˆ«ìë§Œ. ì˜ˆ: 450",
            "INFO_CAR": "íƒ„ìˆ˜í™”ë¬¼(g) ìˆ«ìë§Œ. ì˜ˆ: 35",
            "INFO_PRO": "ë‹¨ë°±ì§ˆ(g) ìˆ«ìë§Œ. ì˜ˆ: 25",
            "INFO_FAT": "ì§€ë°©(g) ìˆ«ìë§Œ. ì˜ˆ: 15",
            "INFO_NA": "ë‚˜íŠ¸ë¥¨(mg) ìˆ«ìë§Œ. ì˜ˆ: 800",
            "HASH_TAG": "ê´€ë ¨ í•´ì‹œíƒœê·¸ 1~2ê°œ. ì˜ˆ: #ë§¤ì½¤ #ê°„ë‹¨ìš”ë¦¬",
            "RCP_PARTS_DTLS": "í•„ìš”í•œ ëª¨ë“  ì¬ë£Œì™€ ì–‘ì„ ìƒì„¸íˆ ë‚˜ì—´. ì˜ˆ: ë¼ì§€ê³ ê¸° 300g, ì–‘íŒŒ 1/2ê°œ, ...",
            "RCP_NA_TIP": "ìš”ë¦¬ì— ëŒ€í•œ ìœ ìš©í•œ íŒ 1~2ì¤„",
            "ATT_FILE_NO_MAIN": "",
            "ATT_FILE_NO_MK": "",
            "MANUAL01": "1ë‹¨ê³„ ì¡°ë¦¬ë²• ì„¤ëª…",
            "MANUAL_IMG01": "",
            "MANUAL02": "2ë‹¨ê³„ ì¡°ë¦¬ë²• ì„¤ëª…",
            "MANUAL_IMG02": "",
            "MANUAL03": "3ë‹¨ê³„ ì¡°ë¦¬ë²• ì„¤ëª…. ì—†ë‹¤ë©´ ë¹ˆ ë¬¸ìì—´",
            "MANUAL_IMG03": "",
            "MANUAL04": "4ë‹¨ê³„ ì¡°ë¦¬ë²• ì„¤ëª…. ì—†ë‹¤ë©´ ë¹ˆ ë¬¸ìì—´",
            "MANUAL_IMG04": "",
            "MANUAL05": "5ë‹¨ê³„ ì¡°ë¦¬ë²• ì„¤ëª…. ì—†ë‹¤ë©´ ë¹ˆ ë¬¸ìì—´",
            "MANUAL_IMG05": "",
            "MANUAL06": "6ë‹¨ê³„ ì¡°ë¦¬ë²• ì„¤ëª…. ì—†ë‹¤ë©´ ë¹ˆ ë¬¸ìì—´",
            "MANUAL_IMG06": "",
            "MANUAL07": "7ë‹¨ê³„ ì¡°ë¦¬ë²• ì„¤ëª…. ì—†ë‹¤ë©´ ë¹ˆ ë¬¸ìì—´",
            "MANUAL_IMG07": "",
            "MANUAL08": "8ë‹¨ê³„ ì¡°ë¦¬ë²• ì„¤ëª…. ì—†ë‹¤ë©´ ë¹ˆ ë¬¸ìì—´",
            "MANUAL_IMG08": "",
            ...ë“±ë“± ìµœëŒ€í•œ ìì„¸í•˜ê²Œ ì¡°ë¦¬ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”. ìµœëŒ€ 20ë‹¨ê³„ê¹Œì§€ ì„¤ëª…ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤ë§Œ, ê¼­ 20ë‹¨ê³„ê¹Œì§€ ì„¤ëª…í•  í•„ìš”ëŠ” ì—†ê³ , ìì—°ìŠ¤ëŸ½ê²Œ ë‹¨ê³„ë¥¼ ë§ì¶°ì£¼ì„¸ìš”.
        }},
        {{
            "RCP_NM": "ë‘ ë²ˆì§¸ ì°½ì˜ì ì¸ í•œê¸€ ìš”ë¦¬ ì´ë¦„",
            "..." : "..."
        }}
    ]
    """
    try:
        # temperatureë¥¼ ì¡°ì ˆí•˜ì—¬ ì°½ì˜ì„±ê³¼ ì¼ê´€ì„± ê· í˜• ë§ì¶”ê¸°
        generation_config = genai.types.GenerationConfig(temperature=0.7)
        response = await gemini_text_model.generate_content_async(
            [prompt], generation_config=generation_config
        )

        # Gemini ì‘ë‹µì—ì„œ JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
        response_text = response.text.strip()
        json_match = re.search(r"\[.*\]", response_text, re.DOTALL)
        if not json_match:
            print("### Gemini ì‘ë‹µì—ì„œ JSON ê°ì²´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return []

        recipes_json = json.loads(json_match.group())

        # ë°˜í™˜ê°’ì´ ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸
        if isinstance(recipes_json, list):
            print(f"### Geminiê°€ {len(recipes_json)}ê°œì˜ ë ˆì‹œí”¼ JSONì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
            return recipes_json
        else:
            print("### Gemini ì‘ë‹µì´ ìœ íš¨í•œ JSON ë°°ì—´ì´ ì•„ë‹™ë‹ˆë‹¤.")
            return []

    except Exception as e:
        print(f"### Gemini API ìš”ì²­ ë˜ëŠ” JSON íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []


# ê³µê³µë°ì´í„° í¬íƒˆ APIë¥¼ ì‚¬ìš©í•´ì„œ ì¡°ë¦¬ì‹í’ˆì˜ ë ˆì‹œí”¼ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë©”ì†Œë“œ
async def fetch_recipe_from_public_api(
    include_ingredients: list, exclude_ingredients: list = None
) -> list:
    # url = f"http://openapi.foodsafetykorea.go.kr/api/f98a399c38a7460fbc05/COOKRCP01/json/1/10/RCP_PARTS_DTLS={','.join(ingredients)}"

    # URL ìˆ˜ë™ ì¡°í•© ë° ì¸ì½”ë”©
    ingredients_str = ",".join(set(include_ingredients))
    encoded_ingredients = urllib.parse.quote(ingredients_str)

    url = (
        f"https://openapi.foodsafetykorea.go.kr/api/{os.getenv('PUBLIC_API_KEY')}/COOKRCP01/json/1/100/"
        f"RCP_PARTS_DTLS={encoded_ingredients}"
    )
    # response = urllib.parse.unquote(url)
    # response_text = response.read().decode("utf-8")
    print(f"\n### ê³µê³µë°ì´í„° API ìš”ì²­ URL: {url}")

    async with httpx.AsyncClient() as client:

        try:
            response = await client.get(url, timeout=10.0)
            response.raise_for_status()  # HTTP ì˜¤ë¥˜ ë°œìƒ ì‹œ ì˜ˆì™¸ ë°œìƒ
            # response = requests.get(url)
            print(
                f"### ê³µê³µë°ì´í„° API ì‘ë‹µ ìƒíƒœ: {response.status_code}, ë‚´ìš©: {response}\n"
            )

            if response.status_code == 200:
                data = response.json()

                all_recipes = []
                if data.get("COOKRCP01") and data["COOKRCP01"].get("row"):
                    all_recipes = data["COOKRCP01"]["row"]

                # ì œì™¸ ì¬ë£Œ í•„í„°ë§ ë¡œì§ ì¶”ê°€
                filtered_recipes = []
                if exclude_ingredients:
                    for recipe in all_recipes:
                        parts_details = recipe.get("RCP_PARTS_DTLS", "").lower()

                        # exclude_ingredients ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì œì™¸
                        if not any(
                            ex_ing.lower() in parts_details
                            for ex_ing in exclude_ingredients
                        ):
                            filtered_recipes.append(recipe)
                else:
                    filtered_recipes = all_recipes

                # ê²°ê³¼ ëœë¤ ì„ê¸°
                random.shuffle(filtered_recipes)

                # í•„í„°ë§í•˜ê³  ìˆœì„œë¥¼ ì„ì€ 'ì›ë³¸ ë ˆì‹œí”¼ ë°ì´í„° ë¦¬ìŠ¤íŠ¸'ë¥¼ ë¦¬í„´
                return filtered_recipes

                # found_recipe = []

                if data.get("COOKRCP01") and data["COOKRCP01"].get("row"):
                    for row in data["COOKRCP01"]["row"]:
                        parts_details = row.get("RCP_PARTS_DTLS", "").lower()
                        if any(
                            ing.lower() in parts_details for ing in include_ingredients
                        ):
                            print("\n### ê³µê³µë°ì´í„° APIì—ì„œ ë ˆì‹œí”¼ ì°¾ìŒ")
                            manuals = {
                                f"MANUAL{i:02d}": row.get(f"MANUAL{i:02d}", "")
                                for i in range(1, 21)
                            }
                            manual_images = {
                                f"MANUAL_IMG{i:02d}": row.get(f"MANUAL_IMG{i:02d}", "")
                                for i in range(1, 21)
                            }

                            # print(f"### manuals: {manuals}")  # ë””ë²„ê¹… ë¡œê·¸
                            # print(f"### manual_images: {manual_images}\n\n")  # ë””ë²„ê¹… ë¡œê·¸

                            manual_entries = {}
                            for key, val in manuals.items():
                                if (
                                    val
                                    and key.startswith("MANUAL")
                                    and key[6:].isdigit()
                                ):
                                    entry_key = f"manual_{key[6:]}"
                                    manual_entries[entry_key] = val

                            manual_img_entries = {}
                            for key, val in manual_images.items():
                                if (
                                    val
                                    and key.startswith("MANUAL_IMG")
                                    and key[10:].isdigit()
                                ):
                                    img_entry_key = f"manual_img_{key[10:]}"
                                    manual_img_entries[img_entry_key] = val

                            print(
                                f"### manual_entries: {manual_entries}"
                            )  # ì¶”ê°€ ë””ë²„ê¹… ë¡œê·¸
                            print(
                                f"### manual_img_entries: {manual_img_entries}\n\n"
                            )  # ì¶”ê°€ ë””ë²„ê¹… ë¡œê·¸

                            recipe_data = {
                                "name": row.get("RCP_NM", "Unknown Recipe"),
                                "cooking_method": row.get("RCP_WAY2", ""),
                                "cuisine_type": row.get("RCP_PAT2", ""),
                                "calories": row.get("INFO_ENG", 0),
                                "info_wgt": (
                                    row.get("INFO_WGT", 0) if row.get("INFO_WGT") else 0
                                ),
                                "info_car": row.get("INFO_CAR", 0),
                                "info_fat": row.get("INFO_FAT", 0),
                                "info_na": row.get("INFO_NA", 0),
                                "info_pro": row.get("INFO_PRO", 0),
                                "hash_tag": row.get("HASH_TAG", ""),
                                "image_main_url": row.get("ATT_FILE_NO_MAIN", ""),
                                "image_thumbnail_url": row.get("ATT_FILE_NO_MK", ""),
                                "tip": row.get("RCP_NA_TIP", ""),
                                "raw_parts_details": row.get("RCP_PARTS_DTLS", ""),
                                **manual_entries,
                                **manual_img_entries,
                            }
                            print(f"### ë§¤ì¹­ëœ ë ˆì‹œí”¼: {recipe_data['name']}\n\n")
                            filtered_recipes.append(recipe_data)
                return filtered_recipes

        except httpx.HTTPError as e:
            print(f"### HTTP ìš”ì²­ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return []

        except json.JSONDecodeError:
            print(f"### JSON íŒŒì‹± ì˜¤ë¥˜. ì„œë²„ ì‘ë‹µì´ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
            print(f"### ìˆ˜ì‹ ëœ í…ìŠ¤íŠ¸: {response.text}")
            return []

    # ì˜ˆì™¸ ë°œìƒí•˜ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    return []


# GEMINIë¥¼ ì‚¬ìš©í•˜ì—¬ ë ˆì‹œí”¼ ì„¤ëª…ì„ ìƒì„±í•˜ëŠ” ë¹„ë™ê¸° í•¨ìˆ˜
async def fetch_recipe_description_from_gemini(
    manuals: list[str], tip: str = ""
) -> str:
    """ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ëŠ” OLLAMAë¥¼ ëŒ€ì‹ í•´ì„œ ì›ë³¸ ë ˆì‹œí”¼ manualsì™€ tipì„ GEMINIê°€ ìƒˆë¡œìš´ ë ˆì‹œí”¼ manualsì™€ tipì„ ìƒì„±"""
    if not gemini_text_model:
        return ""

    # í”„ë¡¬í”„íŠ¸ì— ì¡°ë¦¬ ë‹¨ê³„ì™€ íŒì„ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ì „ë‹¬
    manuals_str = "\n".join(
        [f"ë‹¨ê³„ {i + 1}: {manual}" for i, manual in enumerate(manuals)]
    )

    prompt = f"""
        ë‹¹ì‹ ì€ 'ì¹œì ˆí•œ ìš”ë¦¬ ì„ ìƒë‹˜' ë§íˆ¬ë¡œ ìš”ë¦¬ë²•ì„ ì„¤ëª…í•˜ëŠ” AIì…ë‹ˆë‹¤.
        ì•„ë˜ì˜ [ì›ë³¸ ì¡°ë¦¬ë²•]ê³¼ [ì›ë³¸ íŒ]ì„ ë¶„ì„í•˜ì—¬, ê° ë‹¨ê³„ì™€ íŒì„ ì´ˆë³´ìê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ ìƒì„¸í•œ ì„¤ëª…ìœ¼ë¡œ ì¬ìƒì„±í•´ì£¼ì„¸ìš”.
        
        [ê·œì¹™]
        - ê° ë‹¨ê³„ë³„ ì„¤ëª…ì€ 2~3ì¤„ì˜ ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤.
        - ì‘ë‹µì€ ë°˜ë“œì‹œ ì•„ë˜ [ì¶œë ¥ í˜•ì‹]ì˜ êµ¬ë¶„ì('--- ë‹¨ê³„ êµ¬ë¶„ì„  ---' ë“±)ë¥¼ ì •í™•íˆ ì§€ì¼œì•¼ í•©ë‹ˆë‹¤.
        - êµ¬ë¶„ì ì™¸ì— ë‹¤ë¥¸ ì–´ë–¤ ì„¤ëª…ì´ë‚˜ ë¬¸êµ¬ë„ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.
        
        [ì›ë³¸ ì¡°ë¦¬ë²•]
        {manuals_str}
        
        [ì›ë³¸ íŒ]
        {tip}
        
        [ì¶œë ¥ í˜•ì‹]
        ### ë‹¨ê³„ë³„ ì„¤ëª… ì‹œì‘ ###
        (ì—¬ê¸°ì— 1ë‹¨ê³„ì— ëŒ€í•œ ìƒˆë¡œìš´ ì„¤ëª…ì„ ìƒì„±)
        --- ë‹¨ê³„ êµ¬ë¶„ì„  ---
        (ì—¬ê¸°ì— 2ë‹¨ê³„ì— ëŒ€í•œ ìƒˆë¡œìš´ ì„¤ëª…ì„ ìƒì„±)
        --- ë‹¨ê³„ êµ¬ë¶„ì„  ---
        (ì´ëŸ° ì‹ìœ¼ë¡œ ëª¨ë“  ë‹¨ê³„ì— ëŒ€í•´ ë°˜ë³µ)
        --- ë‹¨ê³„ êµ¬ë¶„ì„  ---
        (ì—¬ê¸°ì— ë§ˆì§€ë§‰ ë‹¨ê³„ì— ëŒ€í•œ ìƒˆë¡œìš´ ì„¤ëª…ì„ ìƒì„±)
        ### ë‹¨ê³„ë³„ ì„¤ëª… ë ###

        ### íŒ ì„¤ëª… ì‹œì‘ ###
        (ì—¬ê¸°ì— íŒì— ëŒ€í•œ ìƒˆë¡œìš´ ì„¤ëª…ì„ ìƒì„±)
        ### íŒ ì„¤ëª… ë ###
    """

    print(
        f"### GEMINI ì„¤ëª… ìƒì„± ì‹œì‘... ì´ {len(manuals)}ë‹¨ê³„, íŒ: {'ìˆìŒ' if tip else 'ì—†ìŒ'}"
    )

    try:
        response = await gemini_text_model.generate_content_async([prompt])
        return response.text.strip()
    except Exception as e:
        print(f"### Gemini íŒ ì„¤ëª… ìƒì„± ì‹¤íŒ¨: {e}")
        return ""

    # # ê° ë‹¨ê³„ë³„ ì„¤ëª… ìƒì„±
    # descriptions = []
    # for i, manual in enumerate(manuals, 1):
    #     if not manual:
    #         continue

    #     prompt = f"ë‹¹ì‹ ì€ ì´ˆë³´ ìš”ë¦¬ì‚¬ë¥¼ ìœ„í•œ ì¹œì ˆí•œ ìš”ë¦¬ ì„ ìƒë‹˜ì…ë‹ˆë‹¤. ë‹¤ìŒì˜ ìš”ë¦¬ ë‹¨ê³„ ì„¤ëª…ì¸ '{manual}'ì„ ë” ì´í•´í•˜ê¸° ì‰½ê³  ì¹œì ˆí•œ ë§íˆ¬ë¡œ 2~3ì¤„ì˜ ìƒì„¸í•œ ì„¤ëª…ìœ¼ë¡œ ë°”ê¿”ì£¼ì„¸ìš”. íŒì´ë‚˜ ì£¼ì˜ì‚¬í•­ì„ í¬í•¨í•˜ë©´ ì¢‹ìŠµë‹ˆë‹¤."

    #     try:
    #         response = await gemini_text_model.generate_content_async([prompt])
    #         generated_text = response.text.strip()
    #         descriptions.append(generated_text)
    #     except Exception as e:
    #         print(f"### Gemini ì„¤ëª… ìƒì„± ì‹¤íŒ¨ (ë‹¨ê³„ {i}): {e}")
    #         None

    # # íŒì— ëŒ€í•œ ì„¤ëª… ì¶”ê°€
    # if tip:
    #     prompt = f"ë‹¤ìŒ ìš”ë¦¬ íŒ '{tip}'ì„ ë” ì¹œì ˆí•˜ê³  ìƒì„¸í•˜ê²Œ í’€ì–´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
    #     try:
    #         response = await gemini_text_model.generate_content_async([prompt])
    #         generated_text = response.text.strip()
    #         descriptions.append(f"**ìš”ë¦¬ íŒ:** {generated_text}")
    #     except Exception as e:
    #         print(f"### Gemini íŒ ì„¤ëª… ìƒì„± ì‹¤íŒ¨: {e}")
    #         None

    # return "\n\n".join(descriptions)


# OLLAMAë¥¼ ì‚¬ìš©í•˜ì—¬ ë ˆì‹œí”¼ ì„¤ëª…ì„ ìƒì„±í•˜ëŠ” ë¹„ë™ê¸° í•¨ìˆ˜
async def fetch_recipe_description_from_ollama(manuals: list, tip: str = None) -> str:
    descriptions = []
    # ollama_url = "http://localhost:11434/api/generate"

    timeout_config = httpx.Timeout(130.0)

    try:
        async with httpx.AsyncClient(timeout=timeout_config) as client:
            for i, manual in enumerate(manuals, 1):

                if not manual:
                    continue

                prompt = f"ë‹¹ì‹ ì€ ìš”ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. {i}ë‹¨ê³„ ë§Œë“œëŠ” ë²• ì„¤ëª…('{manual}')ì„ ì°¸ê³ í•˜ì—¬ ìš”ë¦¬ë¥¼ ì²˜ìŒ í•˜ëŠ” ì‚¬ëŒë„ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì¹œì ˆí•˜ê²Œ 3ì¤„ ì´ë‚´ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”. ì„¤ëª…ì€ ì¼ê´€ë˜ê²Œ ìœ ì§€í•˜ì„¸ìš”."

                payload = {
                    "model": OLLAMA_MODEL,  # ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„
                    "prompt": prompt,
                    "stream": False,  # ìŠ¤íŠ¸ë¦¬ë°ì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
                }

                try:
                    response = await client.post(OLLAMA_API_URL, json=payload)
                    response.raise_for_status()

                    response_data = response.json()
                    generated_text = response_data.get("response", "").strip()

                    if generated_text:
                        descriptions.append(generated_text)
                    else:
                        print(
                            f"### Ollama ì‘ë‹µì— 'response' í‚¤ê°€ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìŒ: {response_data}"
                        )
                        return None

                except httpx.HTTPError as e:
                    print(f"### Ollama API ìš”ì²­ ì˜¤ë¥˜ (ë‹¨ê³„ {i}): {e}")
                    None
                except json.JSONDecodeError:
                    print(
                        f"### Ollama ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨. (ë‹¨ê³„ {i}): ìˆ˜ì‹ ëœ í…ìŠ¤íŠ¸: {response.text}"
                    )
                    None

            # íŒì´ ìˆì„ ê²½ìš° ì¶”ê°€ ì„¤ëª… ìƒì„±
            if tip:
                prompt = f"ë‹¹ì‹ ì€ ìš”ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ìš”ë¦¬ íŒ('{tip}')ì„ ì°¸ê³ í•˜ì—¬ ìš”ë¦¬ë¥¼ ì²˜ìŒ í•˜ëŠ” ì‚¬ëŒë„ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì¹œì ˆí•˜ê²Œ 3ì¤„ ì´ë‚´ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”. ì„¤ëª…ì€ ì¼ê´€ë˜ê²Œ ìœ ì§€í•˜ì„¸ìš”."

                payload = {"model": OLLAMA_MODEL, "prompt": prompt, "stream": False}

                try:
                    response = await client.post(OLLAMA_API_URL, json=payload)
                    response.raise_for_status()

                    response_data = response.json()
                    generated_text = response_data.get("response", "").strip()

                    if generated_text:
                        descriptions.append(f"ìš”ë¦¬ íŒ: {generated_text}")
                except Exception as e:
                    descriptions.append("ìš”ë¦¬ íŒ ì„¤ëª… ìƒì„± ëª»í•¨")
                    print(f"### Ollama íŒ ì„¤ëª… ìƒì„± ì‹¤íŒ¨: {e}")

            return "\n".join(descriptions)

    except Exception as e:
        print(f"### fetch_recipe_description_from_ollama ë©”ì†Œë“œì—ì„œ ì˜ˆì™¸ ë°œìƒ: {e}")
        return None


# ì•ˆì”€
# def generate_ollama_description(manuals, user_id, recipe_id, tip=None):
#     ollama_desc = fetch_recipe_description_from_ollama(manuals, tip)
#     if user_id:
#         import db

#         db.save_ollama_description(user_id, recipe_id, ollama_desc)
#     return ollama_desc


# def fetch_recipe_from_rag(ingredients):
#     service = build("customsearch", "v1", developerKey="your_google_api_key")
#     query = f"recipe with {','.join(ingredients)} site:*.kr -inurl:(login)"
#     res = service.cse().list(q=query, cx="your_google_cse_id", num=3).execute()
#     if res.get("items"):
#         search_result = res["items"][0]["snippet"]
#         prompt = f"ë‹¹ì‹ ì€ ìš”ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ê²€ìƒ‰ ê²°ê³¼({search_result})ì™€ ì¬ë£Œ({','.join(ingredients)})ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìš”ë¦¬ë¥¼ ì²˜ìŒ í•˜ëŠ” ì‚¬ëŒë„ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë ˆì‹œí”¼ë¥¼ 3ì¤„ ì´ë‚´ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
#         response = requests.post(
#             "http://localhost:11434/api/generate",
#             json={"model": "gemma:2b", "prompt": prompt},
#         ).json()
#         return {
#             "name": f"{ingredients[0]}-based Recipe",
#             "ingredients": [{"name": ing, "quantity": ""} for ing in ingredients],
#             "instructions": [
#                 {"step_num": 1, "description": desc}
#                 for desc in response.get("response", "No recipe").split("\n")
#                 if desc
#             ],
#             "description": response.get("response", "No description"),
#         }
#     return None
